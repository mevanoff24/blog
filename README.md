# blog
Blog posts for my Medium Blog

### Interpret the "black box"(LINK NEEDED)
I can't stand when people say that machine learning models are consider to be a "black box". There are actually many way to interpret a machine learning model. Machine learning models shouldn't be consider a "black box" anymore when it comes to actually deriving insight in how these models can assist companies and benefit humanity.Here in this post, the three questions that I want to answer: 
- How does the `feature_importance_` method in sklearn models work. Can we replicate these results?
- How can we build an 'objective based' model that we can actually determine how this prediction was computed? Can we interpret this 'black box' model? 
- What is the best interpretation library and technique? Lets compare different model interpretation techniques
